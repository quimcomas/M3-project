Building XCeption model...

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, None, None, 1 512         conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, None, None, 1 0           block2_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, None, None, 1 0           add_1[0][0]                      
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, None, None, 2 32768       add_1[0][0]                      
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, None, None, 2 0           add_2[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, None, None, 7 186368      add_2[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, None, None, 7 2912        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, None, None, 7 0           add_7[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_8 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_11 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        
                                                                 add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, None, None, 7 0           add_11[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, None, None, 1 745472      add_11[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, None, None, 1 4096        conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_12 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_12[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
global_max_pooling2d_1 (GlobalM (None, 1536)         0           block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          786944      global_max_pooling2d_1[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           fc2[0][0]                        
__________________________________________________________________________________________________
fc3 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           fc3[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 8)            4104        dropout_2[0][0]                  
==================================================================================================
Total params: 18,747,440
Trainable params: 18,697,008
Non-trainable params: 50,432
__________________________________________________________________________________________________
None
Done!

Start training...

Found 400 images belonging to 8 classes.
Found 2288 images belonging to 8 classes.
Epoch 1/50

 1/12 [=>............................] - ETA: 35s - loss: 2.0990 - acc: 0.1250
 5/12 [===========>..................] - ETA: 4s - loss: 2.1070 - acc: 0.0938 
 8/12 [===================>..........] - ETA: 1s - loss: 2.1254 - acc: 0.1289
12/12 [==============================] - 8s 703ms/step - loss: 2.1134 - acc: 0.1710 - val_loss: 2.2660 - val_acc: 0.1263
Epoch 2/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0860 - acc: 0.1250
 2/12 [====>.........................] - ETA: 0s - loss: 2.0579 - acc: 0.1562
 3/12 [======>.......................] - ETA: 0s - loss: 2.0340 - acc: 0.1667
 4/12 [=========>....................] - ETA: 0s - loss: 2.0198 - acc: 0.1797
 5/12 [===========>..................] - ETA: 0s - loss: 2.0422 - acc: 0.1750
 6/12 [==============>...............] - ETA: 0s - loss: 2.0639 - acc: 0.1719
 7/12 [================>.............] - ETA: 0s - loss: 2.0496 - acc: 0.1741
 8/12 [===================>..........] - ETA: 0s - loss: 2.0439 - acc: 0.1758
10/12 [========================>.....] - ETA: 0s - loss: 2.0423 - acc: 0.1812
11/12 [==========================>...] - ETA: 0s - loss: 2.0474 - acc: 0.1790
12/12 [==============================] - 6s 471ms/step - loss: 2.0369 - acc: 0.1901 - val_loss: 2.3240 - val_acc: 0.1831
Epoch 3/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0571 - acc: 0.2188
 3/12 [======>.......................] - ETA: 0s - loss: 1.9775 - acc: 0.2500
 4/12 [=========>....................] - ETA: 0s - loss: 1.9742 - acc: 0.2188
 5/12 [===========>..................] - ETA: 0s - loss: 1.9568 - acc: 0.2500
 6/12 [==============>...............] - ETA: 0s - loss: 1.9369 - acc: 0.2604
 7/12 [================>.............] - ETA: 0s - loss: 1.9428 - acc: 0.2723
 8/12 [===================>..........] - ETA: 0s - loss: 1.9409 - acc: 0.2773
 9/12 [=====================>........] - ETA: 0s - loss: 1.9346 - acc: 0.2812
10/12 [========================>.....] - ETA: 0s - loss: 1.9423 - acc: 0.2750
12/12 [==============================] - 6s 482ms/step - loss: 1.9505 - acc: 0.2857 - val_loss: 2.3710 - val_acc: 0.1356
Epoch 4/50

 1/12 [=>............................] - ETA: 0s - loss: 1.8783 - acc: 0.3125
 4/12 [=========>....................] - ETA: 0s - loss: 1.8881 - acc: 0.2969
 5/12 [===========>..................] - ETA: 0s - loss: 1.9324 - acc: 0.2938
 6/12 [==============>...............] - ETA: 0s - loss: 1.9116 - acc: 0.3021
 7/12 [================>.............] - ETA: 0s - loss: 1.9353 - acc: 0.3036
 8/12 [===================>..........] - ETA: 0s - loss: 1.9362 - acc: 0.3047
 9/12 [=====================>........] - ETA: 0s - loss: 1.9250 - acc: 0.3056
10/12 [========================>.....] - ETA: 0s - loss: 1.9433 - acc: 0.2938
11/12 [==========================>...] - ETA: 0s - loss: 1.9339 - acc: 0.3011
12/12 [==============================] - 5s 454ms/step - loss: 1.9262 - acc: 0.3021 - val_loss: 2.2992 - val_acc: 0.1977
Epoch 5/50

 1/12 [=>............................] - ETA: 0s - loss: 1.8626 - acc: 0.3125
 5/12 [===========>..................] - ETA: 0s - loss: 1.7637 - acc: 0.3375
 6/12 [==============>...............] - ETA: 0s - loss: 1.7891 - acc: 0.3385
 7/12 [================>.............] - ETA: 0s - loss: 1.7936 - acc: 0.3482
 8/12 [===================>..........] - ETA: 0s - loss: 1.8018 - acc: 0.3555
 9/12 [=====================>........] - ETA: 0s - loss: 1.7929 - acc: 0.3542
10/12 [========================>.....] - ETA: 0s - loss: 1.7916 - acc: 0.3563
11/12 [==========================>...] - ETA: 0s - loss: 1.7825 - acc: 0.3665
12/12 [==============================] - 6s 468ms/step - loss: 1.7713 - acc: 0.3726 - val_loss: 3.4494 - val_acc: 0.1339
Epoch 6/50

 1/12 [=>............................] - ETA: 0s - loss: 1.9352 - acc: 0.2500
 4/12 [=========>....................] - ETA: 0s - loss: 1.8508 - acc: 0.3672
 6/12 [==============>...............] - ETA: 0s - loss: 1.7458 - acc: 0.4115
 7/12 [================>.............] - ETA: 0s - loss: 1.7197 - acc: 0.4062
 8/12 [===================>..........] - ETA: 0s - loss: 1.7228 - acc: 0.4141
 9/12 [=====================>........] - ETA: 0s - loss: 1.7079 - acc: 0.4340
10/12 [========================>.....] - ETA: 0s - loss: 1.6976 - acc: 0.4406
11/12 [==========================>...] - ETA: 0s - loss: 1.7067 - acc: 0.4290
12/12 [==============================] - 6s 479ms/step - loss: 1.6883 - acc: 0.4427 - val_loss: 2.4241 - val_acc: 0.1454
Done!

Saving the model into xception_finetuning.h5 

Done!

Start fine-tuning...
recompiling the model with new layer training rules...
Epoch 1/50

 1/12 [=>............................] - ETA: 1:09 - loss: 1.9990 - acc: 0.1250
 3/12 [======>.......................] - ETA: 19s - loss: 1.9392 - acc: 0.2396 
 5/12 [===========>..................] - ETA: 9s - loss: 1.9594 - acc: 0.2313 
 7/12 [================>.............] - ETA: 4s - loss: 1.9720 - acc: 0.2321
 8/12 [===================>..........] - ETA: 3s - loss: 1.9857 - acc: 0.2188
10/12 [========================>.....] - ETA: 1s - loss: 1.9327 - acc: 0.2562
12/12 [==============================] - 12s 1s/step - loss: 1.9030 - acc: 0.2739 - val_loss: 3.8754 - val_acc: 0.2584
Epoch 2/50

 1/12 [=>............................] - ETA: 0s - loss: 1.6423 - acc: 0.3438
 2/12 [====>.........................] - ETA: 0s - loss: 1.6222 - acc: 0.3750
 3/12 [======>.......................] - ETA: 0s - loss: 1.5531 - acc: 0.4271
 4/12 [=========>....................] - ETA: 0s - loss: 1.5542 - acc: 0.3984
 5/12 [===========>..................] - ETA: 0s - loss: 1.5368 - acc: 0.4000
 6/12 [==============>...............] - ETA: 0s - loss: 1.4953 - acc: 0.4010
 7/12 [================>.............] - ETA: 0s - loss: 1.4784 - acc: 0.4018
 8/12 [===================>..........] - ETA: 0s - loss: 1.4631 - acc: 0.4062
 9/12 [=====================>........] - ETA: 0s - loss: 1.4446 - acc: 0.4132
10/12 [========================>.....] - ETA: 0s - loss: 1.4074 - acc: 0.4344
11/12 [==========================>...] - ETA: 0s - loss: 1.3909 - acc: 0.4347
12/12 [==============================] - 6s 492ms/step - loss: 1.3818 - acc: 0.4401 - val_loss: 1.8031 - val_acc: 0.4317
Epoch 3/50

 1/12 [=>............................] - ETA: 0s - loss: 1.7555 - acc: 0.3125
 3/12 [======>.......................] - ETA: 0s - loss: 1.4540 - acc: 0.5104
 4/12 [=========>....................] - ETA: 0s - loss: 1.3390 - acc: 0.5234
 5/12 [===========>..................] - ETA: 0s - loss: 1.2898 - acc: 0.5500
 6/12 [==============>...............] - ETA: 0s - loss: 1.2314 - acc: 0.5625
 8/12 [===================>..........] - ETA: 0s - loss: 1.2178 - acc: 0.5352
 9/12 [=====================>........] - ETA: 0s - loss: 1.1750 - acc: 0.5556
10/12 [========================>.....] - ETA: 0s - loss: 1.1606 - acc: 0.5656
11/12 [==========================>...] - ETA: 0s - loss: 1.1526 - acc: 0.5739
12/12 [==============================] - 6s 481ms/step - loss: 1.1541 - acc: 0.5789 - val_loss: 1.4157 - val_acc: 0.5461
Epoch 4/50

 1/12 [=>............................] - ETA: 0s - loss: 1.0030 - acc: 0.5312
 2/12 [====>.........................] - ETA: 0s - loss: 1.1229 - acc: 0.5000
 3/12 [======>.......................] - ETA: 0s - loss: 1.3171 - acc: 0.4479
 4/12 [=========>....................] - ETA: 0s - loss: 1.2524 - acc: 0.5078
 5/12 [===========>..................] - ETA: 0s - loss: 1.1792 - acc: 0.5437
 6/12 [==============>...............] - ETA: 0s - loss: 1.1045 - acc: 0.5833
 7/12 [================>.............] - ETA: 0s - loss: 1.0653 - acc: 0.6071
 8/12 [===================>..........] - ETA: 0s - loss: 1.0361 - acc: 0.6133
 9/12 [=====================>........] - ETA: 0s - loss: 1.0564 - acc: 0.6146
10/12 [========================>.....] - ETA: 0s - loss: 1.0689 - acc: 0.6156
11/12 [==========================>...] - ETA: 0s - loss: 1.0419 - acc: 0.6307
12/12 [==============================] - 6s 485ms/step - loss: 1.0004 - acc: 0.6484 - val_loss: 1.1245 - val_acc: 0.6330
Epoch 5/50

 1/12 [=>............................] - ETA: 0s - loss: 1.6876 - acc: 0.5000
 3/12 [======>.......................] - ETA: 0s - loss: 1.1600 - acc: 0.6562
 5/12 [===========>..................] - ETA: 0s - loss: 1.1127 - acc: 0.6438
 6/12 [==============>...............] - ETA: 0s - loss: 1.0133 - acc: 0.6823
 7/12 [================>.............] - ETA: 0s - loss: 0.9870 - acc: 0.6652
 8/12 [===================>..........] - ETA: 0s - loss: 0.9402 - acc: 0.6836
 9/12 [=====================>........] - ETA: 0s - loss: 0.9095 - acc: 0.6910
10/12 [========================>.....] - ETA: 0s - loss: 0.9026 - acc: 0.6969
11/12 [==========================>...] - ETA: 0s - loss: 0.8730 - acc: 0.7102
12/12 [==============================] - 6s 477ms/step - loss: 0.8522 - acc: 0.7201 - val_loss: 1.2948 - val_acc: 0.5745
Epoch 6/50

 1/12 [=>............................] - ETA: 0s - loss: 0.8379 - acc: 0.6875
 2/12 [====>.........................] - ETA: 0s - loss: 0.9862 - acc: 0.6562
 3/12 [======>.......................] - ETA: 0s - loss: 0.8293 - acc: 0.7083
 4/12 [=========>....................] - ETA: 0s - loss: 0.7418 - acc: 0.7344
 5/12 [===========>..................] - ETA: 0s - loss: 0.8196 - acc: 0.7250
 6/12 [==============>...............] - ETA: 0s - loss: 0.8164 - acc: 0.7344
 7/12 [================>.............] - ETA: 0s - loss: 0.7840 - acc: 0.7455
 8/12 [===================>..........] - ETA: 0s - loss: 0.7588 - acc: 0.7578
 9/12 [=====================>........] - ETA: 0s - loss: 0.7239 - acc: 0.7674
10/12 [========================>.....] - ETA: 0s - loss: 0.6865 - acc: 0.7812
12/12 [==============================] - 6s 480ms/step - loss: 0.6998 - acc: 0.7763 - val_loss: 1.3093 - val_acc: 0.5771
Epoch 7/50

 1/12 [=>............................] - ETA: 0s - loss: 0.3779 - acc: 0.8750
 3/12 [======>.......................] - ETA: 0s - loss: 0.4549 - acc: 0.8750
 5/12 [===========>..................] - ETA: 0s - loss: 0.5571 - acc: 0.8250
 7/12 [================>.............] - ETA: 0s - loss: 0.5307 - acc: 0.8259
 8/12 [===================>..........] - ETA: 0s - loss: 0.4938 - acc: 0.8359
 9/12 [=====================>........] - ETA: 0s - loss: 0.4636 - acc: 0.8438
10/12 [========================>.....] - ETA: 0s - loss: 0.4922 - acc: 0.8438
11/12 [==========================>...] - ETA: 0s - loss: 0.4814 - acc: 0.8409
12/12 [==============================] - 5s 438ms/step - loss: 0.4926 - acc: 0.8330 - val_loss: 1.0692 - val_acc: 0.6618
Epoch 8/50

 1/12 [=>............................] - ETA: 0s - loss: 0.2476 - acc: 0.9062
 2/12 [====>.........................] - ETA: 0s - loss: 0.3685 - acc: 0.8906
 3/12 [======>.......................] - ETA: 0s - loss: 0.4240 - acc: 0.8750
 5/12 [===========>..................] - ETA: 0s - loss: 0.4080 - acc: 0.8812
 7/12 [================>.............] - ETA: 0s - loss: 0.4642 - acc: 0.8705
 8/12 [===================>..........] - ETA: 0s - loss: 0.4575 - acc: 0.8672
 9/12 [=====================>........] - ETA: 0s - loss: 0.4366 - acc: 0.8750
10/12 [========================>.....] - ETA: 0s - loss: 0.4223 - acc: 0.8781
11/12 [==========================>...] - ETA: 0s - loss: 0.4178 - acc: 0.8778
12/12 [==============================] - 5s 433ms/step - loss: 0.3968 - acc: 0.8826 - val_loss: 1.2440 - val_acc: 0.6090
Epoch 9/50

 1/12 [=>............................] - ETA: 0s - loss: 0.4393 - acc: 0.7500
 2/12 [====>.........................] - ETA: 0s - loss: 0.4760 - acc: 0.8125
 4/12 [=========>....................] - ETA: 0s - loss: 0.3918 - acc: 0.8594
 5/12 [===========>..................] - ETA: 0s - loss: 0.3527 - acc: 0.8750
 7/12 [================>.............] - ETA: 0s - loss: 0.3352 - acc: 0.8929
 8/12 [===================>..........] - ETA: 0s - loss: 0.3234 - acc: 0.8945
 9/12 [=====================>........] - ETA: 0s - loss: 0.3456 - acc: 0.8924
10/12 [========================>.....] - ETA: 0s - loss: 0.3266 - acc: 0.8969
11/12 [==========================>...] - ETA: 0s - loss: 0.3026 - acc: 0.9062
12/12 [==============================] - 5s 424ms/step - loss: 0.3028 - acc: 0.9036 - val_loss: 1.1880 - val_acc: 0.6184
Epoch 10/50

 1/12 [=>............................] - ETA: 0s - loss: 0.1787 - acc: 0.9375
 2/12 [====>.........................] - ETA: 0s - loss: 0.3665 - acc: 0.8594
 3/12 [======>.......................] - ETA: 0s - loss: 0.3625 - acc: 0.8646
 4/12 [=========>....................] - ETA: 0s - loss: 0.3182 - acc: 0.8828
 5/12 [===========>..................] - ETA: 0s - loss: 0.2833 - acc: 0.8938
 6/12 [==============>...............] - ETA: 0s - loss: 0.2892 - acc: 0.9062
 7/12 [================>.............] - ETA: 0s - loss: 0.3581 - acc: 0.8929
 8/12 [===================>..........] - ETA: 0s - loss: 0.3943 - acc: 0.8828
 9/12 [=====================>........] - ETA: 0s - loss: 0.4690 - acc: 0.8785
10/12 [========================>.....] - ETA: 0s - loss: 0.4750 - acc: 0.8781
11/12 [==========================>...] - ETA: 0s - loss: 0.4394 - acc: 0.8864
12/12 [==============================] - 6s 461ms/step - loss: 0.4484 - acc: 0.8857 - val_loss: 1.4054 - val_acc: 0.6028
Epoch 11/50

 1/12 [=>............................] - ETA: 0s - loss: 0.3314 - acc: 0.8438
 2/12 [====>.........................] - ETA: 0s - loss: 0.3115 - acc: 0.8906
 3/12 [======>.......................] - ETA: 0s - loss: 0.3585 - acc: 0.8854
 4/12 [=========>....................] - ETA: 0s - loss: 0.3387 - acc: 0.8984
 5/12 [===========>..................] - ETA: 0s - loss: 0.3330 - acc: 0.8938
 6/12 [==============>...............] - ETA: 0s - loss: 0.3237 - acc: 0.8906
 7/12 [================>.............] - ETA: 0s - loss: 0.3200 - acc: 0.8973
 8/12 [===================>..........] - ETA: 0s - loss: 0.2970 - acc: 0.9062
 9/12 [=====================>........] - ETA: 0s - loss: 0.2955 - acc: 0.9028
10/12 [========================>.....] - ETA: 0s - loss: 0.3146 - acc: 0.9000
11/12 [==========================>...] - ETA: 0s - loss: 0.3284 - acc: 0.8977
12/12 [==============================] - 6s 459ms/step - loss: 0.3037 - acc: 0.9064 - val_loss: 1.8061 - val_acc: 0.5612
Epoch 12/50

 1/12 [=>............................] - ETA: 0s - loss: 0.1675 - acc: 0.9688
 2/12 [====>.........................] - ETA: 0s - loss: 0.2849 - acc: 0.9062
 3/12 [======>.......................] - ETA: 0s - loss: 0.2620 - acc: 0.9062
 4/12 [=========>....................] - ETA: 0s - loss: 0.2484 - acc: 0.9141
 5/12 [===========>..................] - ETA: 0s - loss: 0.2630 - acc: 0.9062
 6/12 [==============>...............] - ETA: 0s - loss: 0.2327 - acc: 0.9219
 7/12 [================>.............] - ETA: 0s - loss: 0.2311 - acc: 0.9241
 8/12 [===================>..........] - ETA: 0s - loss: 0.2497 - acc: 0.9180
 9/12 [=====================>........] - ETA: 0s - loss: 0.2360 - acc: 0.9201
10/12 [========================>.....] - ETA: 0s - loss: 0.2344 - acc: 0.9250
11/12 [==========================>...] - ETA: 0s - loss: 0.2665 - acc: 0.9176
12/12 [==============================] - 5s 458ms/step - loss: 0.2880 - acc: 0.9167 - val_loss: 1.8715 - val_acc: 0.5408
Done!

Saving the model into xception_finetuning.h5 

Done!

Done!
