Building XCeption model...

__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, None, None, 3 0                                            
__________________________________________________________________________________________________
block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    
__________________________________________________________________________________________________
block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               
__________________________________________________________________________________________________
block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            
__________________________________________________________________________________________________
block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           
__________________________________________________________________________________________________
block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               
__________________________________________________________________________________________________
block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            
__________________________________________________________________________________________________
block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            
__________________________________________________________________________________________________
block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           
__________________________________________________________________________________________________
block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, None, None, 1 512         conv2d_1[0][0]                   
__________________________________________________________________________________________________
add_1 (Add)                     (None, None, None, 1 0           block2_pool[0][0]                
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
block3_sepconv1_act (Activation (None, None, None, 1 0           add_1[0][0]                      
__________________________________________________________________________________________________
block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            
__________________________________________________________________________________________________
block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, None, None, 2 32768       add_1[0][0]                      
__________________________________________________________________________________________________
block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, None, None, 2 1024        conv2d_2[0][0]                   
__________________________________________________________________________________________________
add_2 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                
                                                                 batch_normalization_2[0][0]      
__________________________________________________________________________________________________
block4_sepconv1_act (Activation (None, None, None, 2 0           add_2[0][0]                      
__________________________________________________________________________________________________
block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            
__________________________________________________________________________________________________
block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, None, None, 7 186368      add_2[0][0]                      
__________________________________________________________________________________________________
block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, None, None, 7 2912        conv2d_3[0][0]                   
__________________________________________________________________________________________________
add_3 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
block5_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      
__________________________________________________________________________________________________
block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            
__________________________________________________________________________________________________
block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            
__________________________________________________________________________________________________
block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            
__________________________________________________________________________________________________
add_4 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      
__________________________________________________________________________________________________
block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            
__________________________________________________________________________________________________
block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            
__________________________________________________________________________________________________
block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            
__________________________________________________________________________________________________
add_5 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         
                                                                 add_4[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      
__________________________________________________________________________________________________
block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            
__________________________________________________________________________________________________
block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            
__________________________________________________________________________________________________
block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            
__________________________________________________________________________________________________
add_6 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      
__________________________________________________________________________________________________
block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            
__________________________________________________________________________________________________
block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            
__________________________________________________________________________________________________
block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            
__________________________________________________________________________________________________
add_7 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         
                                                                 add_6[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1_act (Activation (None, None, None, 7 0           add_7[0][0]                      
__________________________________________________________________________________________________
block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            
__________________________________________________________________________________________________
block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            
__________________________________________________________________________________________________
block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         
__________________________________________________________________________________________________
block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        
__________________________________________________________________________________________________
block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            
__________________________________________________________________________________________________
add_8 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      
__________________________________________________________________________________________________
block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           
__________________________________________________________________________________________________
block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           
__________________________________________________________________________________________________
block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           
__________________________________________________________________________________________________
add_9 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        
                                                                 add_8[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      
__________________________________________________________________________________________________
block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           
__________________________________________________________________________________________________
block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           
__________________________________________________________________________________________________
block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           
__________________________________________________________________________________________________
add_10 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        
                                                                 add_9[0][0]                      
__________________________________________________________________________________________________
block12_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     
__________________________________________________________________________________________________
block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           
__________________________________________________________________________________________________
block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           
__________________________________________________________________________________________________
block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       
__________________________________________________________________________________________________
block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           
__________________________________________________________________________________________________
add_11 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        
                                                                 add_10[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1_act (Activatio (None, None, None, 7 0           add_11[0][0]                     
__________________________________________________________________________________________________
block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           
__________________________________________________________________________________________________
block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       
__________________________________________________________________________________________________
block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, None, None, 1 745472      add_11[0][0]                     
__________________________________________________________________________________________________
block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, None, None, 1 4096        conv2d_4[0][0]                   
__________________________________________________________________________________________________
add_12 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               
                                                                 batch_normalization_4[0][0]      
__________________________________________________________________________________________________
block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_12[0][0]                     
__________________________________________________________________________________________________
block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           
__________________________________________________________________________________________________
block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        
__________________________________________________________________________________________________
global_max_pooling2d_1 (GlobalM (None, 1536)         0           block14_sepconv1_act[0][0]       
__________________________________________________________________________________________________
fc2 (Dense)                     (None, 512)          786944      global_max_pooling2d_1[0][0]     
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           fc2[0][0]                        
__________________________________________________________________________________________________
fc3 (Dense)                     (None, 512)          262656      dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 512)          0           fc3[0][0]                        
__________________________________________________________________________________________________
predictions (Dense)             (None, 8)            4104        dropout_2[0][0]                  
==================================================================================================
Total params: 18,747,440
Trainable params: 18,697,008
Non-trainable params: 50,432
__________________________________________________________________________________________________
None
Done!

Start training...

Found 400 images belonging to 8 classes.
Found 2288 images belonging to 8 classes.
Epoch 1/50

 1/12 [=>............................] - ETA: 35s - loss: 2.0838 - acc: 0.0938
 5/12 [===========>..................] - ETA: 4s - loss: 2.1122 - acc: 0.1437 
 6/12 [==============>...............] - ETA: 3s - loss: 2.0948 - acc: 0.1615
11/12 [==========================>...] - ETA: 0s - loss: 2.0881 - acc: 0.1506
12/12 [==============================] - 8s 686ms/step - loss: 2.0910 - acc: 0.1481 - val_loss: 2.8831 - val_acc: 0.1158
Epoch 2/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0547 - acc: 0.2188
 2/12 [====>.........................] - ETA: 1s - loss: 2.0687 - acc: 0.1562
 3/12 [======>.......................] - ETA: 0s - loss: 2.1274 - acc: 0.1771
 4/12 [=========>....................] - ETA: 0s - loss: 2.1202 - acc: 0.2109
 5/12 [===========>..................] - ETA: 0s - loss: 2.1207 - acc: 0.1875
 6/12 [==============>...............] - ETA: 0s - loss: 2.1320 - acc: 0.1875
 7/12 [================>.............] - ETA: 0s - loss: 2.0830 - acc: 0.2054
 8/12 [===================>..........] - ETA: 0s - loss: 2.1008 - acc: 0.2070
 9/12 [=====================>........] - ETA: 0s - loss: 2.0865 - acc: 0.2222
10/12 [========================>.....] - ETA: 0s - loss: 2.1084 - acc: 0.2156
11/12 [==========================>...] - ETA: 0s - loss: 2.0971 - acc: 0.2188
12/12 [==============================] - 6s 487ms/step - loss: 2.0880 - acc: 0.2210 - val_loss: 2.2251 - val_acc: 0.1441
Epoch 3/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0477 - acc: 0.0938
 3/12 [======>.......................] - ETA: 0s - loss: 2.0605 - acc: 0.1458
 4/12 [=========>....................] - ETA: 0s - loss: 2.0483 - acc: 0.1562
 5/12 [===========>..................] - ETA: 0s - loss: 2.0403 - acc: 0.1625
 6/12 [==============>...............] - ETA: 0s - loss: 2.0574 - acc: 0.1667
 8/12 [===================>..........] - ETA: 0s - loss: 2.0384 - acc: 0.1836
 9/12 [=====================>........] - ETA: 0s - loss: 2.0279 - acc: 0.1875
10/12 [========================>.....] - ETA: 0s - loss: 2.0251 - acc: 0.1906
11/12 [==========================>...] - ETA: 0s - loss: 2.0233 - acc: 0.1989
12/12 [==============================] - 6s 511ms/step - loss: 2.0223 - acc: 0.2056 - val_loss: 2.2135 - val_acc: 0.1343
Epoch 4/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0876 - acc: 0.0938
 4/12 [=========>....................] - ETA: 0s - loss: 2.0041 - acc: 0.2031
 5/12 [===========>..................] - ETA: 0s - loss: 2.0172 - acc: 0.2125
 6/12 [==============>...............] - ETA: 0s - loss: 2.0138 - acc: 0.2292
 7/12 [================>.............] - ETA: 0s - loss: 2.0017 - acc: 0.2366
 8/12 [===================>..........] - ETA: 0s - loss: 1.9851 - acc: 0.2383
 9/12 [=====================>........] - ETA: 0s - loss: 1.9813 - acc: 0.2396
10/12 [========================>.....] - ETA: 0s - loss: 1.9703 - acc: 0.2437
11/12 [==========================>...] - ETA: 0s - loss: 1.9750 - acc: 0.2443
12/12 [==============================] - 6s 488ms/step - loss: 1.9847 - acc: 0.2498 - val_loss: 2.4958 - val_acc: 0.1684
Epoch 5/50

 1/12 [=>............................] - ETA: 0s - loss: 1.8724 - acc: 0.2812
 4/12 [=========>....................] - ETA: 0s - loss: 1.8709 - acc: 0.2969
 5/12 [===========>..................] - ETA: 0s - loss: 1.8890 - acc: 0.2812
 6/12 [==============>...............] - ETA: 0s - loss: 1.8837 - acc: 0.2865
 7/12 [================>.............] - ETA: 0s - loss: 1.8779 - acc: 0.2946
 8/12 [===================>..........] - ETA: 0s - loss: 1.8635 - acc: 0.3047
 9/12 [=====================>........] - ETA: 0s - loss: 1.8627 - acc: 0.3021
10/12 [========================>.....] - ETA: 0s - loss: 1.8556 - acc: 0.3125
11/12 [==========================>...] - ETA: 0s - loss: 1.8521 - acc: 0.3068
12/12 [==============================] - 6s 471ms/step - loss: 1.8634 - acc: 0.2943 - val_loss: 2.7125 - val_acc: 0.1126
Epoch 6/50

 1/12 [=>............................] - ETA: 0s - loss: 1.8872 - acc: 0.3438
 5/12 [===========>..................] - ETA: 0s - loss: 1.8947 - acc: 0.2437
 6/12 [==============>...............] - ETA: 0s - loss: 1.9040 - acc: 0.2396
 7/12 [================>.............] - ETA: 0s - loss: 1.8887 - acc: 0.2545
 8/12 [===================>..........] - ETA: 0s - loss: 1.8987 - acc: 0.2656
 9/12 [=====================>........] - ETA: 0s - loss: 1.8933 - acc: 0.2708
10/12 [========================>.....] - ETA: 0s - loss: 1.8792 - acc: 0.2875
11/12 [==========================>...] - ETA: 0s - loss: 1.8975 - acc: 0.2812
12/12 [==============================] - 5s 435ms/step - loss: 1.8834 - acc: 0.2944 - val_loss: 3.0128 - val_acc: 0.1179
Epoch 7/50

 1/12 [=>............................] - ETA: 0s - loss: 2.0183 - acc: 0.1875
 5/12 [===========>..................] - ETA: 0s - loss: 1.9469 - acc: 0.2687
 7/12 [================>.............] - ETA: 0s - loss: 1.9116 - acc: 0.2812
 8/12 [===================>..........] - ETA: 0s - loss: 1.8641 - acc: 0.3047
 9/12 [=====================>........] - ETA: 0s - loss: 1.8547 - acc: 0.3264
10/12 [========================>.....] - ETA: 0s - loss: 1.8637 - acc: 0.3125
11/12 [==========================>...] - ETA: 0s - loss: 1.8455 - acc: 0.3210
12/12 [==============================] - 5s 444ms/step - loss: 1.8509 - acc: 0.3254 - val_loss: 2.7278 - val_acc: 0.1755
Epoch 8/50

 1/12 [=>............................] - ETA: 0s - loss: 1.7909 - acc: 0.3438
 5/12 [===========>..................] - ETA: 0s - loss: 1.8382 - acc: 0.2875
 8/12 [===================>..........] - ETA: 0s - loss: 1.8293 - acc: 0.2969
 9/12 [=====================>........] - ETA: 0s - loss: 1.8204 - acc: 0.3125
10/12 [========================>.....] - ETA: 0s - loss: 1.8035 - acc: 0.3219
11/12 [==========================>...] - ETA: 0s - loss: 1.8323 - acc: 0.3097
12/12 [==============================] - 5s 436ms/step - loss: 1.8158 - acc: 0.3151 - val_loss: 2.5195 - val_acc: 0.2043
Done!

Saving the model into xception_finetuning.h5 

Done!

Start fine-tuning...
recompiling the model with new layer training rules...
Epoch 1/50

 1/12 [=>............................] - ETA: 1:08 - loss: 1.9564 - acc: 0.2500
 2/12 [====>.........................] - ETA: 31s - loss: 1.9708 - acc: 0.2812 
 4/12 [=========>....................] - ETA: 12s - loss: 1.9939 - acc: 0.2891
 6/12 [==============>...............] - ETA: 6s - loss: 1.9827 - acc: 0.2604 
 8/12 [===================>..........] - ETA: 3s - loss: 1.9875 - acc: 0.2578
10/12 [========================>.....] - ETA: 1s - loss: 1.9580 - acc: 0.2656
11/12 [==========================>...] - ETA: 0s - loss: 1.9309 - acc: 0.2841
12/12 [==============================] - 12s 972ms/step - loss: 1.9365 - acc: 0.2862 - val_loss: 9.2031 - val_acc: 0.1915
Epoch 2/50

 1/12 [=>............................] - ETA: 0s - loss: 1.7489 - acc: 0.3750
 2/12 [====>.........................] - ETA: 1s - loss: 1.7190 - acc: 0.3438
 3/12 [======>.......................] - ETA: 0s - loss: 1.6939 - acc: 0.3646
 4/12 [=========>....................] - ETA: 0s - loss: 1.6777 - acc: 0.3672
 5/12 [===========>..................] - ETA: 0s - loss: 1.6572 - acc: 0.3875
 6/12 [==============>...............] - ETA: 0s - loss: 1.6129 - acc: 0.4062
 7/12 [================>.............] - ETA: 0s - loss: 1.6098 - acc: 0.4241
 8/12 [===================>..........] - ETA: 0s - loss: 1.5965 - acc: 0.4297
 9/12 [=====================>........] - ETA: 0s - loss: 1.5734 - acc: 0.4410
10/12 [========================>.....] - ETA: 0s - loss: 1.5594 - acc: 0.4500
11/12 [==========================>...] - ETA: 0s - loss: 1.5131 - acc: 0.4688
12/12 [==============================] - 7s 545ms/step - loss: 1.4843 - acc: 0.4844 - val_loss: 6.6417 - val_acc: 0.3107
Epoch 3/50

 1/12 [=>............................] - ETA: 0s - loss: 1.7708 - acc: 0.3125
 2/12 [====>.........................] - ETA: 0s - loss: 1.8164 - acc: 0.2812
 3/12 [======>.......................] - ETA: 0s - loss: 1.5913 - acc: 0.3750
 4/12 [=========>....................] - ETA: 0s - loss: 1.5663 - acc: 0.3906
 5/12 [===========>..................] - ETA: 0s - loss: 1.4518 - acc: 0.4375
 6/12 [==============>...............] - ETA: 0s - loss: 1.6043 - acc: 0.4062
 7/12 [================>.............] - ETA: 0s - loss: 1.6044 - acc: 0.4018
 8/12 [===================>..........] - ETA: 0s - loss: 1.5841 - acc: 0.4180
 9/12 [=====================>........] - ETA: 0s - loss: 1.5330 - acc: 0.4410
10/12 [========================>.....] - ETA: 0s - loss: 1.5008 - acc: 0.4594
11/12 [==========================>...] - ETA: 0s - loss: 1.4621 - acc: 0.4773
12/12 [==============================] - 7s 545ms/step - loss: 1.4370 - acc: 0.4860 - val_loss: 3.8346 - val_acc: 0.3843
Epoch 4/50

 1/12 [=>............................] - ETA: 0s - loss: 1.1035 - acc: 0.6562
 2/12 [====>.........................] - ETA: 0s - loss: 1.3007 - acc: 0.6250
 3/12 [======>.......................] - ETA: 0s - loss: 1.2452 - acc: 0.5938
 4/12 [=========>....................] - ETA: 0s - loss: 1.1699 - acc: 0.6016
 5/12 [===========>..................] - ETA: 0s - loss: 1.1124 - acc: 0.6250
 6/12 [==============>...............] - ETA: 0s - loss: 1.0829 - acc: 0.6250
 7/12 [================>.............] - ETA: 0s - loss: 1.0671 - acc: 0.6295
 8/12 [===================>..........] - ETA: 0s - loss: 1.0702 - acc: 0.6328
 9/12 [=====================>........] - ETA: 0s - loss: 1.0773 - acc: 0.6319
10/12 [========================>.....] - ETA: 0s - loss: 1.0673 - acc: 0.6375
11/12 [==========================>...] - ETA: 0s - loss: 1.0724 - acc: 0.6364
12/12 [==============================] - 6s 511ms/step - loss: 1.0636 - acc: 0.6300 - val_loss: 2.2859 - val_acc: 0.4920
Epoch 5/50

 1/12 [=>............................] - ETA: 0s - loss: 0.8712 - acc: 0.6250
 3/12 [======>.......................] - ETA: 0s - loss: 0.8702 - acc: 0.6979
 4/12 [=========>....................] - ETA: 0s - loss: 0.8969 - acc: 0.7031
 5/12 [===========>..................] - ETA: 0s - loss: 0.9105 - acc: 0.6813
 6/12 [==============>...............] - ETA: 0s - loss: 0.9035 - acc: 0.7031
 7/12 [================>.............] - ETA: 0s - loss: 0.9473 - acc: 0.6875
 8/12 [===================>..........] - ETA: 0s - loss: 0.9059 - acc: 0.6992
 9/12 [=====================>........] - ETA: 0s - loss: 0.9147 - acc: 0.7153
11/12 [==========================>...] - ETA: 0s - loss: 0.8731 - acc: 0.7330
12/12 [==============================] - 6s 483ms/step - loss: 0.8852 - acc: 0.7239 - val_loss: 1.5958 - val_acc: 0.5727
Epoch 6/50

 1/12 [=>............................] - ETA: 0s - loss: 0.8921 - acc: 0.6562
 3/12 [======>.......................] - ETA: 0s - loss: 0.9310 - acc: 0.6875
 5/12 [===========>..................] - ETA: 0s - loss: 0.9546 - acc: 0.6875
 6/12 [==============>...............] - ETA: 0s - loss: 0.9512 - acc: 0.6875
 7/12 [================>.............] - ETA: 0s - loss: 0.9479 - acc: 0.6920
 8/12 [===================>..........] - ETA: 0s - loss: 0.9220 - acc: 0.6992
 9/12 [=====================>........] - ETA: 0s - loss: 0.9128 - acc: 0.6979
10/12 [========================>.....] - ETA: 0s - loss: 0.8877 - acc: 0.7063
11/12 [==========================>...] - ETA: 0s - loss: 0.8916 - acc: 0.7045
12/12 [==============================] - 6s 474ms/step - loss: 0.8864 - acc: 0.7083 - val_loss: 1.7340 - val_acc: 0.5448
Epoch 7/50

 1/12 [=>............................] - ETA: 0s - loss: 0.9456 - acc: 0.6250
 2/12 [====>.........................] - ETA: 0s - loss: 0.7594 - acc: 0.7188
 3/12 [======>.......................] - ETA: 0s - loss: 0.7229 - acc: 0.7500
 4/12 [=========>....................] - ETA: 0s - loss: 0.7621 - acc: 0.7344
 5/12 [===========>..................] - ETA: 0s - loss: 0.7541 - acc: 0.7375
 6/12 [==============>...............] - ETA: 0s - loss: 0.8772 - acc: 0.7083
 7/12 [================>.............] - ETA: 0s - loss: 0.8512 - acc: 0.7054
 8/12 [===================>..........] - ETA: 0s - loss: 0.8055 - acc: 0.7188
 9/12 [=====================>........] - ETA: 0s - loss: 0.8563 - acc: 0.7014
10/12 [========================>.....] - ETA: 0s - loss: 0.8394 - acc: 0.7125
11/12 [==========================>...] - ETA: 0s - loss: 0.8278 - acc: 0.7188
12/12 [==============================] - 6s 488ms/step - loss: 0.8193 - acc: 0.7184 - val_loss: 1.5814 - val_acc: 0.6020
Epoch 8/50

 1/12 [=>............................] - ETA: 0s - loss: 0.6980 - acc: 0.7188
 2/12 [====>.........................] - ETA: 0s - loss: 0.7563 - acc: 0.6719
 3/12 [======>.......................] - ETA: 0s - loss: 0.7549 - acc: 0.6875
 4/12 [=========>....................] - ETA: 0s - loss: 0.7725 - acc: 0.7031
 5/12 [===========>..................] - ETA: 0s - loss: 0.7717 - acc: 0.7125
 6/12 [==============>...............] - ETA: 0s - loss: 0.7485 - acc: 0.7188
 8/12 [===================>..........] - ETA: 0s - loss: 0.7134 - acc: 0.7461
 9/12 [=====================>........] - ETA: 0s - loss: 0.6924 - acc: 0.7569
10/12 [========================>.....] - ETA: 0s - loss: 0.6868 - acc: 0.7656
11/12 [==========================>...] - ETA: 0s - loss: 0.7060 - acc: 0.7642
12/12 [==============================] - 6s 460ms/step - loss: 0.7287 - acc: 0.7578 - val_loss: 1.2257 - val_acc: 0.6361
Epoch 9/50

 1/12 [=>............................] - ETA: 0s - loss: 0.6763 - acc: 0.7812
 2/12 [====>.........................] - ETA: 0s - loss: 0.7326 - acc: 0.7500
 3/12 [======>.......................] - ETA: 0s - loss: 0.6626 - acc: 0.7708
 4/12 [=========>....................] - ETA: 0s - loss: 0.7737 - acc: 0.7344
 5/12 [===========>..................] - ETA: 0s - loss: 0.7481 - acc: 0.7375
 6/12 [==============>...............] - ETA: 0s - loss: 0.7825 - acc: 0.7396
 7/12 [================>.............] - ETA: 0s - loss: 0.7853 - acc: 0.7500
 8/12 [===================>..........] - ETA: 0s - loss: 0.7769 - acc: 0.7461
 9/12 [=====================>........] - ETA: 0s - loss: 0.7859 - acc: 0.7431
10/12 [========================>.....] - ETA: 0s - loss: 0.7781 - acc: 0.7500
11/12 [==========================>...] - ETA: 0s - loss: 0.7549 - acc: 0.7557
12/12 [==============================] - 6s 474ms/step - loss: 0.7344 - acc: 0.7661 - val_loss: 1.1745 - val_acc: 0.6263
Epoch 10/50

 1/12 [=>............................] - ETA: 0s - loss: 0.5564 - acc: 0.8125
 2/12 [====>.........................] - ETA: 0s - loss: 0.5122 - acc: 0.8281
 3/12 [======>.......................] - ETA: 0s - loss: 0.7397 - acc: 0.7500
 4/12 [=========>....................] - ETA: 0s - loss: 0.7312 - acc: 0.7344
 5/12 [===========>..................] - ETA: 0s - loss: 0.6742 - acc: 0.7625
 6/12 [==============>...............] - ETA: 0s - loss: 0.6676 - acc: 0.7604
 7/12 [================>.............] - ETA: 0s - loss: 0.7003 - acc: 0.7366
 8/12 [===================>..........] - ETA: 0s - loss: 0.6770 - acc: 0.7539
 9/12 [=====================>........] - ETA: 0s - loss: 0.6695 - acc: 0.7604
10/12 [========================>.....] - ETA: 0s - loss: 0.6820 - acc: 0.7594
11/12 [==========================>...] - ETA: 0s - loss: 0.6959 - acc: 0.7614
12/12 [==============================] - 6s 487ms/step - loss: 0.6778 - acc: 0.7679 - val_loss: 1.1240 - val_acc: 0.6352
Epoch 11/50

 1/12 [=>............................] - ETA: 0s - loss: 1.0933 - acc: 0.6875
 2/12 [====>.........................] - ETA: 0s - loss: 0.8130 - acc: 0.7656
 3/12 [======>.......................] - ETA: 0s - loss: 0.7217 - acc: 0.7708
 4/12 [=========>....................] - ETA: 0s - loss: 0.7241 - acc: 0.7500
 5/12 [===========>..................] - ETA: 0s - loss: 0.7528 - acc: 0.7562
 6/12 [==============>...............] - ETA: 0s - loss: 0.7479 - acc: 0.7552
 7/12 [================>.............] - ETA: 0s - loss: 0.7910 - acc: 0.7366
 8/12 [===================>..........] - ETA: 0s - loss: 0.7470 - acc: 0.7578
 9/12 [=====================>........] - ETA: 0s - loss: 0.7346 - acc: 0.7535
10/12 [========================>.....] - ETA: 0s - loss: 0.7113 - acc: 0.7656
11/12 [==========================>...] - ETA: 0s - loss: 0.6982 - acc: 0.7699
12/12 [==============================] - 6s 465ms/step - loss: 0.6985 - acc: 0.7711 - val_loss: 1.7511 - val_acc: 0.5696
Epoch 12/50

 1/12 [=>............................] - ETA: 0s - loss: 1.3922 - acc: 0.5938
 2/12 [====>.........................] - ETA: 0s - loss: 0.8928 - acc: 0.7500
 3/12 [======>.......................] - ETA: 0s - loss: 0.7632 - acc: 0.7917
 4/12 [=========>....................] - ETA: 0s - loss: 0.6721 - acc: 0.8203
 5/12 [===========>..................] - ETA: 0s - loss: 0.6555 - acc: 0.8187
 6/12 [==============>...............] - ETA: 0s - loss: 0.6856 - acc: 0.7969
 7/12 [================>.............] - ETA: 0s - loss: 0.6681 - acc: 0.8036
 8/12 [===================>..........] - ETA: 0s - loss: 0.7091 - acc: 0.7969
 9/12 [=====================>........] - ETA: 0s - loss: 0.6950 - acc: 0.7951
10/12 [========================>.....] - ETA: 0s - loss: 0.6768 - acc: 0.8000
11/12 [==========================>...] - ETA: 0s - loss: 0.6756 - acc: 0.7955
12/12 [==============================] - 6s 467ms/step - loss: 0.6716 - acc: 0.7944 - val_loss: 1.6815 - val_acc: 0.5652
Epoch 13/50

 1/12 [=>............................] - ETA: 0s - loss: 0.4883 - acc: 0.9062
 3/12 [======>.......................] - ETA: 0s - loss: 0.7140 - acc: 0.8333
 5/12 [===========>..................] - ETA: 0s - loss: 0.7509 - acc: 0.7688
 6/12 [==============>...............] - ETA: 0s - loss: 0.7246 - acc: 0.7708
 7/12 [================>.............] - ETA: 0s - loss: 0.7057 - acc: 0.7768
 8/12 [===================>..........] - ETA: 0s - loss: 0.6751 - acc: 0.7891
 9/12 [=====================>........] - ETA: 0s - loss: 0.6838 - acc: 0.7882
10/12 [========================>.....] - ETA: 0s - loss: 0.6864 - acc: 0.7844
11/12 [==========================>...] - ETA: 0s - loss: 0.7078 - acc: 0.7727
12/12 [==============================] - 6s 477ms/step - loss: 0.6844 - acc: 0.7787 - val_loss: 1.5644 - val_acc: 0.5869
Epoch 14/50

 1/12 [=>............................] - ETA: 0s - loss: 0.5417 - acc: 0.8750
 3/12 [======>.......................] - ETA: 0s - loss: 0.5884 - acc: 0.8125
 4/12 [=========>....................] - ETA: 0s - loss: 0.5761 - acc: 0.8203
 5/12 [===========>..................] - ETA: 0s - loss: 0.5475 - acc: 0.8438
 6/12 [==============>...............] - ETA: 0s - loss: 0.5870 - acc: 0.8333
 7/12 [================>.............] - ETA: 0s - loss: 0.5657 - acc: 0.8438
 9/12 [=====================>........] - ETA: 0s - loss: 0.5664 - acc: 0.8472
11/12 [==========================>...] - ETA: 0s - loss: 0.5887 - acc: 0.8381
12/12 [==============================] - 5s 443ms/step - loss: 0.5802 - acc: 0.8390 - val_loss: 1.2509 - val_acc: 0.6472
Epoch 15/50

 1/12 [=>............................] - ETA: 0s - loss: 0.3765 - acc: 0.8438
 2/12 [====>.........................] - ETA: 1s - loss: 0.6447 - acc: 0.7500
 3/12 [======>.......................] - ETA: 0s - loss: 0.6049 - acc: 0.7500
 4/12 [=========>....................] - ETA: 0s - loss: 0.5923 - acc: 0.7734
 5/12 [===========>..................] - ETA: 0s - loss: 0.5658 - acc: 0.7875
 6/12 [==============>...............] - ETA: 0s - loss: 0.5641 - acc: 0.7917
 8/12 [===================>..........] - ETA: 0s - loss: 0.7314 - acc: 0.7539
 9/12 [=====================>........] - ETA: 0s - loss: 0.7361 - acc: 0.7569
10/12 [========================>.....] - ETA: 0s - loss: 0.7001 - acc: 0.7656
11/12 [==========================>...] - ETA: 0s - loss: 0.6884 - acc: 0.7699
12/12 [==============================] - 5s 440ms/step - loss: 0.6728 - acc: 0.7719 - val_loss: 1.2912 - val_acc: 0.6073
Done!

Saving the model into xception_finetuning.h5 

Done!

Done!
